#!/usr/bin/env python3
"""
115ç½‘ç›˜æ–‡ä»¶ç§»åŠ¨å·¥å…· - Dockerç‰ˆæœ¬
æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®æ‰€æœ‰å‚æ•°
"""

from pathlib import Path
from p115client import P115Client
from p115client.tool.iterdir import iter_files, iter_dirs
import time
import logging
from datetime import datetime
import re
import os
from logging.handlers import TimedRotatingFileHandler
from functools import wraps
import signal
from contextlib import contextmanager
import requests


# å…¨å±€å˜é‡
client = None
logger = None
LOG_DIR = "/app/logs"
DATA_DIR = "/app/data"
COOKIE_FILE = os.path.join(DATA_DIR, "115-cookies.txt")

# é»˜è®¤è¶…æ—¶å’Œé‡è¯•é…ç½®
DEFAULT_API_TIMEOUT = 120  # é»˜è®¤120ç§’è¶…æ—¶
DEFAULT_API_RETRY_TIMES = 3  # é»˜è®¤é‡è¯•3æ¬¡
BARK_URL = None  # Barké€šçŸ¥URL
CALLBACK_URL = None  # æ–‡ä»¶ç§»åŠ¨åçš„å›è°ƒURL


class TimeoutError(Exception):
    """è¶…æ—¶å¼‚å¸¸"""
    pass


@contextmanager
def timeout_handler(seconds):
    """
    è¶…æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆä»…é™Unix/Linuxç³»ç»Ÿï¼‰
    
    å‚æ•°:
        seconds: è¶…æ—¶ç§’æ•°
    """
    def timeout_signal_handler(signum, frame):
        raise TimeoutError(f"æ“ä½œè¶…æ—¶ ({seconds}ç§’)")
    
    # Windowsç³»ç»Ÿä¸æ”¯æŒsignal.alarmï¼Œç›´æ¥è¿”å›
    if os.name == 'nt':
        yield
        return
    
    # è®¾ç½®ä¿¡å·å¤„ç†å™¨
    old_handler = signal.signal(signal.SIGALRM, timeout_signal_handler)
    signal.alarm(seconds)
    
    try:
        yield
    finally:
        signal.alarm(0)
        signal.signal(signal.SIGALRM, old_handler)


def with_retry_and_timeout(max_retries=None, timeout_seconds=None, operation_name="æ“ä½œ"):
    """
    ä¸ºå‡½æ•°æ·»åŠ è¶…æ—¶å’Œé‡è¯•æœºåˆ¶çš„è£…é¥°å™¨
    
    å‚æ•°:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å…¨å±€é…ç½®
        timeout_seconds: è¶…æ—¶ç§’æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å…¨å±€é…ç½®
        operation_name: æ“ä½œåç§°ï¼Œç”¨äºæ—¥å¿—è¾“å‡º
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # è·å–å…¨å±€é…ç½®
            retries = max_retries if max_retries is not None else DEFAULT_API_RETRY_TIMES
            timeout = timeout_seconds if timeout_seconds is not None else DEFAULT_API_TIMEOUT
            
            last_error = None
            
            for attempt in range(retries):
                try:
                    # Windowsç³»ç»Ÿç›´æ¥æ‰§è¡Œï¼Œä¸ä½¿ç”¨ä¿¡å·è¶…æ—¶
                    if os.name == 'nt':
                        return func(*args, **kwargs)
                    
                    # Unix/Linuxç³»ç»Ÿä½¿ç”¨ä¿¡å·è¶…æ—¶
                    with timeout_handler(timeout):
                        return func(*args, **kwargs)
                        
                except TimeoutError as e:
                    last_error = e
                    if attempt < retries - 1:
                        wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´
                        logger.warning(f"âš ï¸  {operation_name}è¶…æ—¶ (å°è¯• {attempt + 1}/{retries})ï¼Œ{wait_time}ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                    else:
                        logger.error(f"âŒ {operation_name}åœ¨ {retries} æ¬¡å°è¯•åä»ç„¶è¶…æ—¶")
                        logger.error("ğŸ’¡ å»ºè®®: å¦‚æœæŒç»­è¶…æ—¶ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–Cookieå·²å¤±æ•ˆ")
                        logger.error("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†è®¾ç½®")
                        logger.error("   2. å°è¯•é‡æ–°è·å–Cookieå¹¶æ›´æ–°é…ç½®")
                        send_bark_notification(
                            f"115è‡ªåŠ¨ç§»åŠ¨å¤±è´¥: {operation_name}",
                            f"æ“ä½œè¶…æ—¶({retries}æ¬¡é‡è¯•åä»å¤±è´¥)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–Cookie",
                            "timeSensitive"
                        )
                        
                except Exception as e:
                    last_error = e
                    error_str = str(e).lower()
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯ï¼ˆä¸é‡è¯•ï¼‰
                    if 'login' in error_str or 'auth' in error_str or 'cookie' in error_str:
                        logger.error(f"âŒ {operation_name}å¤±è´¥: è®¤è¯é”™è¯¯ï¼Œä¸è¿›è¡Œé‡è¯•")
                        raise
                    
                    # å…¶ä»–é”™è¯¯è¿›è¡Œé‡è¯•
                    if attempt < retries - 1:
                        wait_time = (attempt + 1) * 2
                        logger.warning(f"âš ï¸  {operation_name}å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {e}")
                        logger.warning(f"   {wait_time}ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                    else:
                        logger.error(f"âŒ {operation_name}åœ¨ {retries} æ¬¡å°è¯•åä»ç„¶å¤±è´¥: {e}")
                        logger.error("ğŸ’¡ å»ºè®®: å¦‚æœæŒç»­å¤±è´¥ï¼Œå¯èƒ½æ˜¯Cookieå·²å¤±æ•ˆ")
                        logger.error("   è¯·å°è¯•é‡æ–°è·å–Cookieå¹¶æ›´æ–°é…ç½®")
                        send_bark_notification(
                            f"115è‡ªåŠ¨ç§»åŠ¨å¤±è´¥: {operation_name}",
                            f"æ“ä½œå¤±è´¥({retries}æ¬¡é‡è¯•å): {str(e)[:100]}",
                            "timeSensitive"
                        )
            
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
            raise last_error
        
        return wrapper
    return decorator


def setup_logger(log_retention_days=7):
    """
    è®¾ç½®æ—¥å¿—è®°å½•å™¨ï¼ŒæŒ‰å¤©åˆ†å‰²ï¼Œè‡ªåŠ¨æ¸…ç†æ—§æ—¥å¿—
    
    å‚æ•°:
        log_retention_days: æ—¥å¿—ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤7å¤©
    """
    global logger
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)
    
    # åˆ›å»ºlogger
    logger = logging.getLogger('move_items_docker')
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
    logger.handlers.clear()
    
    # æ–‡ä»¶å¤„ç†å™¨ - æŒ‰å¤©åˆ†å‰²
    log_file = os.path.join(LOG_DIR, 'move_items.log')
    file_handler = TimedRotatingFileHandler(
        log_file,
        when='midnight',
        interval=1,
        backupCount=log_retention_days,
        encoding='utf-8'
    )
    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger


def send_bark_notification(title, content, level="passive"):
    """
    å‘é€Barké€šçŸ¥
    
    å‚æ•°:
        title: é€šçŸ¥æ ‡é¢˜
        content: é€šçŸ¥å†…å®¹
        level: é€šçŸ¥çº§åˆ« (active/timeSensitive/passive)
    """
    if not BARK_URL:
        return
    
    try:
        # ç»„åˆå®Œæ•´çš„Bark URL
        url = f"{BARK_URL.rstrip('/')}/{requests.utils.quote(title)}/{requests.utils.quote(content)}?level={level}"
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            logger.info(f"ğŸ“± Barké€šçŸ¥å·²å‘é€: {title}")
        else:
            logger.warning(f"âš ï¸  Barké€šçŸ¥å‘é€å¤±è´¥: HTTP {response.status_code}")
    except Exception as e:
        logger.warning(f"âš ï¸  Barké€šçŸ¥å‘é€å¼‚å¸¸: {e}")


def trigger_callback():
    """
    è§¦å‘å›è°ƒURLï¼Œç”¨äºé€šçŸ¥å¤–éƒ¨ç³»ç»Ÿæ–‡ä»¶å·²ç§»åŠ¨
    """
    if not CALLBACK_URL:
        return
    
    try:
        logger.info(f"ğŸ”” æ­£åœ¨è§¦å‘å›è°ƒ: {CALLBACK_URL}")
        response = requests.get(CALLBACK_URL, timeout=10)
        if response.status_code == 200:
            logger.info(f"âœ… å›è°ƒæˆåŠŸ: HTTP {response.status_code}")
        else:
            logger.warning(f"âš ï¸  å›è°ƒè¿”å›é200: HTTP {response.status_code}")
    except requests.exceptions.Timeout:
        logger.warning(f"âš ï¸  å›è°ƒè¶…æ—¶: {CALLBACK_URL}")
    except Exception as e:
        logger.warning(f"âš ï¸  å›è°ƒå¤±è´¥: {e}")


def parse_path_mappings(mappings_str):
    """
    è§£æè·¯å¾„æ˜ å°„é…ç½®
    
    å‚æ•°:
        mappings_str: æ˜ å°„å­—ç¬¦ä¸²ï¼Œæ ¼å¼: "æºè·¯å¾„1->ç›®æ ‡è·¯å¾„1,æºè·¯å¾„2->ç›®æ ‡è·¯å¾„2"
    
    è¿”å›:
        list: [(æºè·¯å¾„, ç›®æ ‡è·¯å¾„), ...] æˆ–ç©ºåˆ—è¡¨
    """
    if not mappings_str or not mappings_str.strip():
        return []
    
    mappings = []
    pairs = mappings_str.split(',')
    
    for idx, pair in enumerate(pairs, 1):
        pair = pair.strip()
        if not pair:
            continue
            
        if '->' not in pair:
            logger.warning(f"âš ï¸  æ˜ å°„ {idx}: æ ¼å¼é”™è¯¯ï¼ˆç¼ºå°‘ '->'ï¼‰: {pair}")
            logger.warning(f"    æ­£ç¡®æ ¼å¼: /æºè·¯å¾„->/ç›®æ ‡è·¯å¾„")
            continue
        
        parts = pair.split('->', 1)
        if len(parts) != 2:
            logger.warning(f"âš ï¸  æ˜ å°„ {idx}: æ ¼å¼é”™è¯¯: {pair}")
            continue
        
        source = parts[0].strip()
        target = parts[1].strip()
        
        if not source or not target:
            logger.warning(f"âš ï¸  æ˜ å°„ {idx}: è·¯å¾„ä¸èƒ½ä¸ºç©º: {pair}")
            continue
        
        if not source.startswith('/'):
            logger.warning(f"âš ï¸  æ˜ å°„ {idx}: æºè·¯å¾„å¿…é¡»ä»¥ '/' å¼€å¤´: {source}")
            logger.warning(f"    å·²è‡ªåŠ¨ä¿®æ­£ä¸º: /{source}")
            source = '/' + source
        
        if not target.startswith('/'):
            logger.warning(f"âš ï¸  æ˜ å°„ {idx}: ç›®æ ‡è·¯å¾„å¿…é¡»ä»¥ '/' å¼€å¤´: {target}")
            logger.warning(f"    å·²è‡ªåŠ¨ä¿®æ­£ä¸º: /{target}")
            target = '/' + target
        
        mappings.append((source, target))
        logger.info(f"âœ“ æ˜ å°„ {idx}: {source} -> {target}")
    
    return mappings


def parse_exclude_extensions(extensions_str):
    """
    è§£ææ’é™¤çš„æ–‡ä»¶åç¼€
    
    å‚æ•°:
        extensions_str: åç¼€å­—ç¬¦ä¸²ï¼Œæ ¼å¼: ".txt,.tmp,.log" æˆ– "txt,tmp,log"
    
    è¿”å›:
        set: åç¼€é›†åˆï¼ˆç»Ÿä¸€å°å†™ï¼ŒåŒ…å«ç‚¹å·ï¼‰
    """
    if not extensions_str or not extensions_str.strip():
        return set()
    
    extensions = set()
    parts = extensions_str.split(',')
    
    for part in parts:
        ext = part.strip().lower()
        if not ext:
            continue
        
        # ç¡®ä¿åç¼€ä»¥ç‚¹å¼€å¤´
        if not ext.startswith('.'):
            ext = '.' + ext
        
        extensions.add(ext)
    
    if extensions:
        logger.info(f"ğŸ“‹ å·²é…ç½®æ’é™¤åç¼€: {', '.join(sorted(extensions))}")
    
    return extensions


def should_exclude_file(filename, exclude_extensions):
    """
    åˆ¤æ–­æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«æ’é™¤
    
    å‚æ•°:
        filename: æ–‡ä»¶å
        exclude_extensions: æ’é™¤çš„åç¼€é›†åˆ
    
    è¿”å›:
        bool: Trueè¡¨ç¤ºåº”è¯¥æ’é™¤ï¼ŒFalseè¡¨ç¤ºä¸æ’é™¤
    """
    if not exclude_extensions:
        return False
    
    # è·å–æ–‡ä»¶åç¼€ï¼ˆå°å†™ï¼‰
    file_ext = os.path.splitext(filename)[1].lower()
    
    return file_ext in exclude_extensions


def format_file_size(size):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
    if size < 1024:
        return f"{size} B"
    elif size < 1024 ** 2:
        return f"{size / 1024:.2f} KB"
    elif size < 1024 ** 3:
        return f"{size / (1024 ** 2):.2f} MB"
    else:
        return f"{size / (1024 ** 3):.2f} GB"


def parse_file_size(size_str):
    """
    è§£ææ–‡ä»¶å¤§å°å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—èŠ‚æ•°
    
    å‚æ•°:
        size_str: æ–‡ä»¶å¤§å°å­—ç¬¦ä¸²ï¼Œå¦‚ "200MB", "1.5GB", "500KB", "100M"
    
    è¿”å›:
        int: å­—èŠ‚æ•°ï¼Œè§£æå¤±è´¥è¿”å› None
    """
    size_str = size_str.strip().upper()
    
    # å®šä¹‰å•ä½è½¬æ¢
    units = {
        'B': 1,
        'KB': 1024,
        'K': 1024,
        'MB': 1024 ** 2,
        'M': 1024 ** 2,
        'GB': 1024 ** 3,
        'G': 1024 ** 3,
        'TB': 1024 ** 4,
        'T': 1024 ** 4,
    }
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ
    pattern = r'^(\d+(?:\.\d+)?)\s*([KMGT]?B?)$'
    match = re.match(pattern, size_str)
    
    if not match:
        return None
    
    value = float(match.group(1))
    unit = match.group(2) or 'B'
    
    if unit not in units:
        return None
    
    return int(value * units[unit])


def find_directory_by_path(path, start_cid=0):
    """
    æ ¹æ®è·¯å¾„æŸ¥æ‰¾ç›®å½•IDï¼ˆå¸¦è¶…æ—¶å’Œé‡è¯•ï¼‰
    
    å‚æ•°:
        path: ç›®å½•è·¯å¾„ï¼Œæ ¼å¼å¦‚ "/folder1/folder2/folder3"
        start_cid: èµ·å§‹ç›®å½•IDï¼Œé»˜è®¤ä¸º 0ï¼ˆæ ¹ç›®å½•ï¼‰
    
    è¿”å›:
        int: ç›®å½•IDï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
    """
    # å¤„ç†è·¯å¾„
    path = path.strip()
    
    # å¦‚æœæ˜¯ç©ºè·¯å¾„æˆ–åªæœ‰ /ï¼Œè¿”å›æ ¹ç›®å½•
    if not path or path == '/':
        return 0
    
    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„æ–œæ 
    path = path.strip('/')
    
    # åˆ†å‰²è·¯å¾„
    path_parts = [p for p in path.split('/') if p]
    
    if not path_parts:
        return start_cid
    
    current_cid = start_cid
    
    # é€å±‚æŸ¥æ‰¾
    for i, folder_name in enumerate(path_parts):
        current_path = '/' + '/'.join(path_parts[:i+1])
        logger.info(f"  ğŸ” æŸ¥æ‰¾: {current_path}")
        
        # è·å–å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•ï¼ˆå¸¦è¶…æ—¶å’Œé‡è¯•ï¼‰
        found = False
        try:
            @with_retry_and_timeout(operation_name=f"æ‰«æç›®å½• {current_path}")
            def scan_subdirs():
                for dir_info in iter_dirs(client=client, cid=current_cid, max_workers=0):
                    if dir_info.get('name') == folder_name:
                        return dir_info.get('id')
                return None
            
            result_cid = scan_subdirs()
            if result_cid:
                current_cid = result_cid
                found = True
                logger.info(f"     âœ“ æ‰¾åˆ° (ID: {current_cid})")
                
        except Exception as e:
            logger.error(f"     âœ— æŸ¥è¯¢ç›®å½•æ—¶å‡ºé”™: {e}")
            return None
        
        if not found:
            logger.error(f"     âœ— æœªæ‰¾åˆ°ç›®å½•: {folder_name}")
            logger.error(f"     æç¤º: è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰")
            return None
    
    return current_cid


def check_cookie_valid():
    """
    æ£€æŸ¥ Cookie æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
    
    è¿”å›:
        bool: True è¡¨ç¤ºæœ‰æ•ˆï¼ŒFalse è¡¨ç¤ºå¤±æ•ˆ
    """
    try:
        user_info = client.user_info()
        if user_info and user_info.get('state'):
            return True
        else:
            return False
    except Exception as e:
        logger.error(f"æ£€æŸ¥ Cookie çŠ¶æ€æ—¶å‡ºé”™: {e}")
        return False


def move_files(file_ids, target_pid=0):
    """
    ç§»åŠ¨æ–‡ä»¶æˆ–ç›®å½•åˆ°æŒ‡å®šç›®å½•ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    
    å‚æ•°:
        file_ids: æ–‡ä»¶æˆ–ç›®å½•ID
        target_pid: ç›®æ ‡ç›®å½•IDï¼Œé»˜è®¤ä¸º 0ï¼ˆæ ¹ç›®å½•ï¼‰
    
    è¿”å›:
        dict: API è¿”å›çš„ç»“æœ
    """
    @with_retry_and_timeout(operation_name="ç§»åŠ¨æ–‡ä»¶")
    def do_move():
        result = client.fs_move(file_ids, pid=target_pid)
        
        # æ£€æŸ¥æ˜¯å¦å› ä¸º Cookie å¤±æ•ˆå¯¼è‡´çš„é”™è¯¯
        if not result.get('state'):
            error_msg = result.get('error', result.get('error_msg', ''))
            # å¸¸è§çš„è®¤è¯å¤±è´¥é”™è¯¯ç æˆ–æ¶ˆæ¯
            if 'login' in error_msg.lower() or 'auth' in error_msg.lower() or result.get('errno') == 99:
                logger.error("=" * 80)
                logger.error("âŒ æ£€æµ‹åˆ° Cookie å¯èƒ½å·²å¤±æ•ˆï¼")
                logger.error("=" * 80)
                logger.error("")
                logger.error("è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤æ›´æ–° Cookieï¼š")
                logger.error("  1. è®¿é—® https://115.com é‡æ–°ç™»å½•")
                logger.error("  2. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·è·å–æ–°çš„ Cookie")
                logger.error("  3. æ›´æ–° docker-compose.yml ä¸­çš„ COOKIE ç¯å¢ƒå˜é‡")
                logger.error("  4. é‡å¯å®¹å™¨: docker-compose restart")
                logger.error("")
                logger.error("=" * 80)
                # æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ä¸Šå±‚è¯†åˆ«ä¸ºè®¤è¯é”™è¯¯
                raise Exception(f"Cookieå¤±æ•ˆ: {error_msg}")
        
        return result
    
    try:
        return do_move()
    except Exception as e:
        logger.error(f"ç§»åŠ¨æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {'state': False, 'error': str(e)}


def init_client_from_env():
    """
    ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–115å®¢æˆ·ç«¯
    
    è¿”å›:
        P115Client: å®¢æˆ·ç«¯å¯¹è±¡ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    global client
    
    logger.info("=" * 80)
    logger.info("ğŸ” 115ç½‘ç›˜å®¢æˆ·ç«¯åˆå§‹åŒ–")
    logger.info("=" * 80)
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–cookie
    cookie_env = os.environ.get('COOKIE', '').strip()
    cookie_source = None
    
    if cookie_env:
        logger.info("ğŸ“ ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ Cookie")
        cookie_source = "ç¯å¢ƒå˜é‡"
    else:
        # å°è¯•ä»æ–‡ä»¶è¯»å–
        if os.path.exists(COOKIE_FILE):
            logger.info(f"ğŸ“‚ ä»æŒä¹…åŒ–æ–‡ä»¶è¯»å– Cookie: {COOKIE_FILE}")
            try:
                with open(COOKIE_FILE, 'r', encoding='utf-8') as f:
                    cookie_env = f.read().strip()
                logger.info("âœ“ Cookie è¯»å–æˆåŠŸ")
                cookie_source = "æŒä¹…åŒ–æ–‡ä»¶"
            except Exception as e:
                logger.error(f"âœ— è¯»å–Cookieæ–‡ä»¶å¤±è´¥: {e}")
                return None
    
    if not cookie_env:
        logger.error("=" * 80)
        logger.error("âŒ é”™è¯¯: æœªè®¾ç½® COOKIE ç¯å¢ƒå˜é‡")
        logger.error("=" * 80)
        logger.error("")
        logger.error("è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½® Cookie:")
        logger.error("  docker run -e COOKIE='ä½ çš„Cookie' ...")
        logger.error("")
        logger.error("å¦‚ä½•è·å– Cookie:")
        logger.error("  1. è®¿é—® https://115.com å¹¶ç™»å½•")
        logger.error("  2. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·")
        logger.error("  3. åˆ‡æ¢åˆ° Network æ ‡ç­¾")
        logger.error("  4. åˆ·æ–°é¡µé¢ï¼Œé€‰æ‹©ä»»æ„è¯·æ±‚")
        logger.error("  5. åœ¨è¯·æ±‚å¤´ä¸­æ‰¾åˆ° Cookie å­—æ®µå¹¶å¤åˆ¶")
        logger.error("")
        return None
    
    # éªŒè¯cookie
    try:
        logger.info("ğŸ”„ æ­£åœ¨éªŒè¯Cookie...")
        client = P115Client(cookie_env)
        
        # æµ‹è¯•è¿æ¥ - å°è¯•è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆæ›´å¿«æ›´å¯é ï¼‰
        try:
            logger.info("ğŸŒ æ­£åœ¨æµ‹è¯•APIè¿æ¥...")
            # ä½¿ç”¨æ›´ç®€å•çš„APIæµ‹è¯•è¿æ¥
            user_info = client.user_info()
            if user_info and user_info.get('state'):
                user_name = user_info.get('data', {}).get('user_name', 'æœªçŸ¥ç”¨æˆ·')
                logger.info("=" * 80)
                logger.info(f"âœ… CookieéªŒè¯æˆåŠŸï¼")
                logger.info(f"ğŸ‘¤ å½“å‰ç”¨æˆ·: {user_name}")
                logger.info("=" * 80)
            else:
                logger.error("=" * 80)
                logger.error("âŒ CookieéªŒè¯å¤±è´¥: æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯")
                logger.error("=" * 80)
                logger.error("")
                logger.error("å¯èƒ½åŸå› :")
                logger.error("  1. Cookie æ ¼å¼é”™è¯¯")
                logger.error("  2. Cookie å·²è¿‡æœŸï¼ˆéœ€è¦é‡æ–°è·å–ï¼‰")
                logger.error("  3. 115è´¦å·å¼‚å¸¸")
                logger.error("")
                return None
        except Exception as e:
            logger.error("=" * 80)
            logger.error(f"âŒ è¿æ¥115 APIå¤±è´¥: {e}")
            logger.error("=" * 80)
            logger.error("")
            logger.error("å¯èƒ½åŸå› :")
            logger.error("  1. ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ— æ³•è®¿é—® 115.com")
            logger.error("  2. Cookie å·²è¿‡æœŸæˆ–æ ¼å¼é”™è¯¯")
            logger.error("  3. è¢«é˜²ç«å¢™æˆ–ä»£ç†æ‹¦æˆª")
            logger.error("")
            logger.error("è§£å†³æ–¹æ¡ˆ:")
            logger.error("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            logger.error("  2. å¦‚æœä½¿ç”¨ä»£ç†ï¼Œæ·»åŠ : network_mode: host")
            logger.error("  3. é‡æ–°è·å– Cookie")
            logger.error("")
            return None
        
        # ä¿å­˜cookieåˆ°æ–‡ä»¶ï¼ˆç”¨äºä¸‹æ¬¡é‡å¯ï¼‰
        try:
            os.makedirs(DATA_DIR, exist_ok=True)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ–‡ä»¶
            need_update = True
            if os.path.exists(COOKIE_FILE):
                with open(COOKIE_FILE, 'r', encoding='utf-8') as f:
                    old_cookie = f.read().strip()
                if old_cookie == cookie_env:
                    need_update = False
            
            if need_update:
                with open(COOKIE_FILE, 'w', encoding='utf-8') as f:
                    f.write(cookie_env)
                if cookie_source == "ç¯å¢ƒå˜é‡":
                    logger.info(f"ğŸ’¾ Cookieå·²æ›´æ–°å¹¶ä¿å­˜åˆ° {COOKIE_FILE}")
                    logger.info("   ï¼ˆç¯å¢ƒå˜é‡ä¸­çš„æ–° Cookie å·²è¦†ç›–æ—§æ–‡ä»¶ï¼‰")
                else:
                    logger.info(f"ğŸ’¾ Cookieå·²ä¿å­˜åˆ° {COOKIE_FILE}")
            else:
                logger.info(f"ğŸ’¾ Cookieæ–‡ä»¶æ— éœ€æ›´æ–°")
        except Exception as e:
            logger.warning(f"âš ï¸  ä¿å­˜Cookieæ–‡ä»¶å¤±è´¥ï¼ˆä¸å½±å“è¿è¡Œï¼‰: {e}")
        
        return client
        
    except Exception as e:
        logger.error("=" * 80)
        logger.error(f"âŒ åˆå§‹åŒ–å®¢æˆ·ç«¯å¤±è´¥: {e}")
        logger.error("=" * 80)
        return None


def auto_move_files_task(path_mappings, interval_minutes, min_size_bytes, exclude_extensions):
    """
    è‡ªåŠ¨ç§»åŠ¨æ–‡ä»¶ä»»åŠ¡ï¼ˆæ”¯æŒå¤šç»„è·¯å¾„æ˜ å°„ï¼‰
    
    å‚æ•°:
        path_mappings: è·¯å¾„æ˜ å°„åˆ—è¡¨ [(æºè·¯å¾„, ç›®æ ‡è·¯å¾„), ...]
        interval_minutes: æ£€æŸ¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
        min_size_bytes: æœ€å°æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        exclude_extensions: æ’é™¤çš„æ–‡ä»¶åç¼€é›†åˆ
    """
    logger.info("=" * 80)
    logger.info("ğŸš€ è‡ªåŠ¨ç§»åŠ¨æ–‡ä»¶ä»»åŠ¡å¯åŠ¨")
    logger.info("=" * 80)
    logger.info(f"ğŸ“Š é…ç½®ä¿¡æ¯:")
    logger.info(f"   â”œâ”€ æ˜ å°„æ•°é‡: {len(path_mappings)} ç»„")
    logger.info(f"   â”œâ”€ æ£€æŸ¥é—´éš”: {interval_minutes} åˆ†é’Ÿ")
    logger.info(f"   â”œâ”€ æœ€å°æ–‡ä»¶: {format_file_size(min_size_bytes)}")
    if exclude_extensions:
        logger.info(f"   â””â”€ æ’é™¤åç¼€: {', '.join(sorted(exclude_extensions))}")
    else:
        logger.info(f"   â””â”€ æ’é™¤åç¼€: æ— ")
    logger.info("")
    
    for idx, (src, tgt) in enumerate(path_mappings, 1):
        logger.info(f"ğŸ“ æ˜ å°„ {idx}: {src} âœ {tgt}")
    logger.info("=" * 80)
    
    # è§£ææ‰€æœ‰è·¯å¾„æ˜ å°„
    mapping_cids = []
    failed_mappings = []
    
    for idx, (source_path, target_path) in enumerate(path_mappings, 1):
        logger.info(f"\nğŸ”„ æ­£åœ¨è§£ææ˜ å°„ {idx}/{len(path_mappings)}: {source_path} âœ {target_path}")
        
        logger.info(f"ğŸ“‚ è§£ææºç›®å½•: {source_path}")
        source_cid = find_directory_by_path(source_path)
        
        if source_cid is None:
            logger.error(f"âŒ æ— æ³•æ‰¾åˆ°æºç›®å½•ï¼Œè·³è¿‡æ­¤æ˜ å°„")
            failed_mappings.append((source_path, target_path, "æºç›®å½•ä¸å­˜åœ¨"))
            continue
        
        logger.info(f"ğŸ“‚ è§£æç›®æ ‡ç›®å½•: {target_path}")
        target_cid = find_directory_by_path(target_path)
        
        if target_cid is None:
            logger.error(f"âŒ æ— æ³•æ‰¾åˆ°ç›®æ ‡ç›®å½•ï¼Œè·³è¿‡æ­¤æ˜ å°„")
            failed_mappings.append((source_path, target_path, "ç›®æ ‡ç›®å½•ä¸å­˜åœ¨"))
            continue
        
        mapping_cids.append({
            'index': idx,
            'source_path': source_path,
            'target_path': target_path,
            'source_cid': source_cid,
            'target_cid': target_cid
        })
        logger.info(f"âœ… æ˜ å°„è§£ææˆåŠŸ")
    
    logger.info("")
    logger.info("=" * 80)
    if mapping_cids:
        logger.info(f"âœ… æˆåŠŸè§£æ {len(mapping_cids)}/{len(path_mappings)} ä¸ªè·¯å¾„æ˜ å°„")
    else:
        logger.error(f"âŒ æ²¡æœ‰æœ‰æ•ˆçš„è·¯å¾„æ˜ å°„")
        
    if failed_mappings:
        logger.warning(f"âš ï¸  å¤±è´¥ {len(failed_mappings)} ä¸ªè·¯å¾„æ˜ å°„:")
        for src, tgt, reason in failed_mappings:
            logger.warning(f"   â”œâ”€ {src} âœ {tgt}")
            logger.warning(f"   â””â”€ åŸå› : {reason}")
    
    if not mapping_cids:
        logger.error("=" * 80)
        logger.error("âŒ ä»»åŠ¡ç»ˆæ­¢: æ²¡æœ‰å¯ç”¨çš„è·¯å¾„æ˜ å°„")
        logger.error("=" * 80)
        return False
    
    logger.info("=" * 80)
    
    # å¼€å§‹å¾ªç¯æ£€æŸ¥
    run_count = 0
    interval_seconds = interval_minutes * 60
    total_moved = 0
    total_failed = 0
    cookie_check_interval = 10  # æ¯10è½®æ£€æŸ¥ä¸€æ¬¡ Cookie
    
    try:
        while True:
            run_count += 1
            
            # å®šæœŸæ£€æŸ¥ Cookie æ˜¯å¦æœ‰æ•ˆ
            if run_count % cookie_check_interval == 1 and run_count > 1:
                logger.info("")
                logger.info("ğŸ” å®šæœŸæ£€æŸ¥ Cookie çŠ¶æ€...")
                if not check_cookie_valid():
                    logger.error("")
                    logger.error("=" * 80)
                    logger.error("âŒ Cookie å·²å¤±æ•ˆï¼ç¨‹åºå°†åœæ­¢è¿è¡Œ")
                    logger.error("=" * 80)
                    logger.error("")
                    logger.error("è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤æ›´æ–° Cookieï¼š")
                    logger.error("  1. è®¿é—® https://115.com é‡æ–°ç™»å½•")
                    logger.error("  2. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·")
                    logger.error("  3. åˆ‡æ¢åˆ° Network æ ‡ç­¾ï¼Œåˆ·æ–°é¡µé¢")
                    logger.error("  4. æ‰¾åˆ°ä»»æ„è¯·æ±‚ï¼Œå¤åˆ¶ Cookie å€¼")
                    logger.error("  5. æ›´æ–°ç¯å¢ƒå˜é‡:")
                    logger.error("     - ä¿®æ”¹ docker-compose.yml ä¸­çš„ COOKIE")
                    logger.error("     - æˆ–åˆ é™¤ data/115-cookies.txt å¹¶é‡å¯å®¹å™¨")
                    logger.error("  6. é‡å¯å®¹å™¨: docker-compose restart")
                    logger.error("")
                    logger.error("=" * 80)
                    return False
                else:
                    logger.info("âœ… Cookie çŠ¶æ€æ­£å¸¸")
            
            logger.info("")
            logger.info("=" * 80)
            logger.info(f"ğŸ”„ ç¬¬ {run_count} æ¬¡æ£€æŸ¥å¼€å§‹")
            logger.info(f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("=" * 80)
            
            round_moved = 0
            round_failed = 0
            
            # å¤„ç†æ¯ä¸ªæ˜ å°„
            for mapping in mapping_cids:
                idx = mapping['index']
                source_path = mapping['source_path']
                target_path = mapping['target_path']
                source_cid = mapping['source_cid']
                target_cid = mapping['target_cid']
                
                logger.info("")
                logger.info(f"ğŸ“¦ å¤„ç†æ˜ å°„ {idx}/{len(mapping_cids)}")
                logger.info(f"   æº: {source_path}")
                logger.info(f"   âœ  {target_path}")
                logger.info("-" * 80)
                
                try:
                    # è·å–æºç›®å½•ä¸­çš„æ–‡ä»¶ï¼ˆå¸¦è¶…æ—¶å’Œé‡è¯•ï¼‰
                    logger.info(f"ğŸ” æ‰«ææºç›®å½• (ID: {source_cid})...")
                    files_to_move = []
                    total_files = 0
                    excluded_files = 0
                    small_files = 0
                    
                    @with_retry_and_timeout(operation_name=f"æ‰«ææ–‡ä»¶åˆ—è¡¨ {source_path}")
                    def scan_source_files():
                        result = []
                        stats = {'total': 0, 'excluded': 0, 'small': 0}
                        
                        for file_info in iter_files(
                            client=client,
                            cid=source_cid,
                            cur=0,  # éå†å­ç›®å½•æ ‘
                            page_size=1000
                        ):
                            stats['total'] += 1
                            file_size = file_info.get('size', 0)
                            file_name = file_info.get('name', '')
                            file_id = file_info.get('id', '')
                            file_path = file_info.get('path', '')
                            
                            # å¦‚æœpathä¸ºç©ºï¼Œä½¿ç”¨nameä½œä¸ºæ˜¾ç¤º
                            display_path = file_path if file_path else file_name
                            
                            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤è¯¥æ–‡ä»¶
                            if should_exclude_file(file_name, exclude_extensions):
                                stats['excluded'] += 1
                                continue
                            
                            # æ£€æŸ¥æ–‡ä»¶å¤§å°
                            if file_size >= min_size_bytes:
                                result.append({
                                    'id': file_id,
                                    'name': file_name,
                                    'size': file_size,
                                    'path': file_path,
                                    'display_path': display_path
                                })
                                logger.info(f"  âœ“ {display_path} ({format_file_size(file_size)})")
                            else:
                                stats['small'] += 1
                        
                        return result, stats
                    
                    try:
                        files_to_move, file_stats = scan_source_files()
                        total_files = file_stats['total']
                        excluded_files = file_stats['excluded']
                        small_files = file_stats['small']
                    except Exception as e:
                        error_str = str(e).lower()
                        if 'login' in error_str or 'auth' in error_str or 'cookie' in error_str:
                            logger.error("")
                            logger.error("=" * 80)
                            logger.error("âŒ æ‰«ææ–‡ä»¶æ—¶æ£€æµ‹åˆ° Cookie å·²å¤±æ•ˆï¼")
                            logger.error("=" * 80)
                            logger.error("")
                            logger.error("è¯·ç«‹å³æ›´æ–° Cookie å¹¶é‡å¯å®¹å™¨")
                            logger.error("è¯¦ç»†æ­¥éª¤è¯·æŸ¥çœ‹ä¸Šæ–¹æ—¥å¿—")
                            logger.error("=" * 80)
                            return False
                        else:
                            # å…¶ä»–é”™è¯¯ï¼ˆåŒ…æ‹¬è¶…æ—¶ï¼‰è®°å½•åç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ˜ å°„
                            logger.error(f"âŒ æ‰«æç›®å½•å¤±è´¥: {e}")
                            logger.warning(f"âš ï¸  è·³è¿‡æ­¤æ˜ å°„ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª...")
                            continue
                    
                    logger.info("")
                    logger.info(f"ğŸ“Š æ‰«æå®Œæˆ:")
                    logger.info(f"   â”œâ”€ æ€»æ–‡ä»¶æ•°: {total_files}")
                    if small_files > 0:
                        logger.info(f"   â”œâ”€ è¿‡å°æ–‡ä»¶: {small_files} (< {format_file_size(min_size_bytes)})")
                    if excluded_files > 0:
                        logger.info(f"   â”œâ”€ æ’é™¤æ–‡ä»¶: {excluded_files} (åç¼€è¿‡æ»¤)")
                    logger.info(f"   â””â”€ å¾…ç§»åŠ¨: {len(files_to_move)}")
                    
                    # ç§»åŠ¨æ–‡ä»¶
                    if files_to_move:
                        logger.info("")
                        logger.info(f"ğŸ“¤ å¼€å§‹ç§»åŠ¨ {len(files_to_move)} ä¸ªæ–‡ä»¶...")
                        logger.info("-" * 80)
                        
                        success_count = 0
                        fail_count = 0
                        
                        for file_info in files_to_move:
                            try:
                                display_info = file_info.get('display_path') or file_info.get('name', 'æœªçŸ¥æ–‡ä»¶')
                                size_info = format_file_size(file_info['size'])
                                logger.info(f"  âœ {display_info}")
                                logger.info(f"     å¤§å°: {size_info}, ID: {file_info['id']}")
                                
                                result = move_files(file_info['id'], target_cid)
                                
                                if result.get('state'):
                                    success_count += 1
                                    logger.info(f"     âœ… æˆåŠŸ")
                                else:
                                    fail_count += 1
                                    error_msg = result.get('error', result.get('error_msg', 'æœªçŸ¥é”™è¯¯'))
                                    logger.error(f"     âŒ å¤±è´¥: {error_msg}")
                                
                                # æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                                time.sleep(0.5)
                                
                            except Exception as e:
                                fail_count += 1
                                logger.error(f"     âŒ å¼‚å¸¸: {e}")
                        
                        logger.info("")
                        logger.info(f"ğŸ“ˆ ç§»åŠ¨ç»“æœ: âœ… æˆåŠŸ {success_count} | âŒ å¤±è´¥ {fail_count}")
                        round_moved += success_count
                        round_failed += fail_count
                    else:
                        logger.info("")
                        logger.info("ğŸ’¤ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶éœ€è¦ç§»åŠ¨")
                    
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†æ˜ å°„æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    import traceback
                    logger.error(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
            
            # æœ¬è½®ç»Ÿè®¡
            total_moved += round_moved
            total_failed += round_failed
            
            logger.info("")
            logger.info("=" * 80)
            logger.info(f"ğŸ“Š æœ¬è½®ç»Ÿè®¡: âœ… ç§»åŠ¨ {round_moved} ä¸ª | âŒ å¤±è´¥ {round_failed} ä¸ª")
            logger.info(f"ğŸ“Š æ€»è®¡ç»Ÿè®¡: âœ… å·²ç§»åŠ¨ {total_moved} ä¸ª | âŒ å¤±è´¥ {total_failed} ä¸ª")
            
            # å¦‚æœæœ¬è½®æœ‰æ–‡ä»¶ç§»åŠ¨ï¼Œè§¦å‘å›è°ƒ
            if round_moved > 0:
                trigger_callback()
            
            # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
            next_check_time = datetime.now().timestamp() + interval_seconds
            next_check_str = datetime.fromtimestamp(next_check_time).strftime('%Y-%m-%d %H:%M:%S')
            
            logger.info(f"â° ä¸‹æ¬¡æ£€æŸ¥: {next_check_str}")
            logger.info(f"ğŸ˜´ ç­‰å¾… {interval_minutes} åˆ†é’Ÿ...")
            logger.info("=" * 80)
            
            time.sleep(interval_seconds)
            
    except KeyboardInterrupt:
        logger.info("")
        logger.info("=" * 80)
        logger.info("ğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œä»»åŠ¡åœæ­¢")
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š è¿è¡Œç»Ÿè®¡:")
        logger.info(f"   â”œâ”€ æ‰§è¡Œæ¬¡æ•°: {run_count}")
        logger.info(f"   â”œâ”€ æˆåŠŸç§»åŠ¨: {total_moved} ä¸ªæ–‡ä»¶")
        logger.info(f"   â””â”€ ç§»åŠ¨å¤±è´¥: {total_failed} ä¸ªæ–‡ä»¶")
        logger.info("=" * 80)
        return True
    except Exception as e:
        logger.error("")
        logger.error("=" * 80)
        logger.error(f"âŒ ä»»åŠ¡å¼‚å¸¸ç»ˆæ­¢: {e}")
        logger.error("=" * 80)
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
        return False


def main():
    """ä¸»å‡½æ•° - Dockerç‰ˆæœ¬"""
    
    global DEFAULT_API_TIMEOUT, DEFAULT_API_RETRY_TIMES, BARK_URL, CALLBACK_URL
    
    # è¯»å–ç¯å¢ƒå˜é‡
    source_path = os.environ.get('SOURCE_PATH', '').strip()
    target_path = os.environ.get('TARGET_PATH', '').strip()
    path_mappings_str = os.environ.get('PATH_MAPPINGS', '').strip()
    exclude_extensions_str = os.environ.get('EXCLUDE_EXTENSIONS', '').strip()
    check_interval = os.environ.get('CHECK_INTERVAL', '5').strip()
    min_file_size = os.environ.get('MIN_FILE_SIZE', '200MB').strip()
    log_retention_days = os.environ.get('LOG_RETENTION_DAYS', '7').strip()
    mode = os.environ.get('MODE', 'auto').strip().lower()
    
    # è¯»å–è¶…æ—¶å’Œé‡è¯•é…ç½®
    api_timeout = os.environ.get('API_TIMEOUT', str(DEFAULT_API_TIMEOUT)).strip()
    api_retry_times = os.environ.get('API_RETRY_TIMES', str(DEFAULT_API_RETRY_TIMES)).strip()
    
    # è¯»å–Barké€šçŸ¥é…ç½®
    bark_url = os.environ.get('BARK_URL', '').strip()
    
    # è¯»å–å›è°ƒURLé…ç½®
    callback_url = os.environ.get('CALLBACK_URL', '').strip()
    
    # è®¾ç½®æ—¥å¿—
    try:
        log_days = int(log_retention_days)
        if log_days < 1:
            log_days = 7
    except:
        log_days = 7
    
    setup_logger(log_days)
    
    # è®¾ç½®å…¨å±€å˜é‡ï¼ˆåœ¨loggeråˆå§‹åŒ–ä¹‹åï¼‰
    if bark_url:
        BARK_URL = bark_url
        logger.info(f"ğŸ“± Barké€šçŸ¥å·²å¯ç”¨")
    
    if callback_url:
        CALLBACK_URL = callback_url
        logger.info(f"ğŸ”” æ–‡ä»¶ç§»åŠ¨å›è°ƒå·²å¯ç”¨: {CALLBACK_URL}")
    
    logger.info("")
    logger.info("=" * 80)
    logger.info("ğŸš€ 115ç½‘ç›˜æ–‡ä»¶ç§»åŠ¨å·¥å…· - Dockerç‰ˆæœ¬")
    logger.info("=" * 80)
    logger.info(f"ğŸ“… å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"ğŸ“ æ—¥å¿—ä¿ç•™: {log_days} å¤©")
    logger.info(f"ğŸ”§ è¿è¡Œæ¨¡å¼: {mode}")
    
    # è§£æå’Œè®¾ç½®è¶…æ—¶é…ç½®
    try:
        timeout_val = int(api_timeout)
        if timeout_val < 10:
            logger.warning(f"âš ï¸  API_TIMEOUT å€¼ {timeout_val} ç§’è¿‡çŸ­ï¼Œå·²è°ƒæ•´ä¸ºæœ€å°å€¼ 10 ç§’")
            timeout_val = 10
        DEFAULT_API_TIMEOUT = timeout_val
        logger.info(f"â±ï¸  APIè¶…æ—¶: {DEFAULT_API_TIMEOUT} ç§’")
    except:
        logger.warning(f"âš ï¸  API_TIMEOUT å€¼æ— æ•ˆ: {api_timeout}ï¼Œä½¿ç”¨é»˜è®¤å€¼ {DEFAULT_API_TIMEOUT} ç§’")
    
    # è§£æå’Œè®¾ç½®é‡è¯•é…ç½®
    try:
        retry_val = int(api_retry_times)
        if retry_val < 1:
            logger.warning(f"âš ï¸  API_RETRY_TIMES å€¼ {retry_val} è¿‡å°ï¼Œå·²è°ƒæ•´ä¸ºæœ€å°å€¼ 1")
            retry_val = 1
        elif retry_val > 10:
            logger.warning(f"âš ï¸  API_RETRY_TIMES å€¼ {retry_val} è¿‡å¤§ï¼Œå·²è°ƒæ•´ä¸ºæœ€å¤§å€¼ 10")
            retry_val = 10
        DEFAULT_API_RETRY_TIMES = retry_val
        logger.info(f"ğŸ”„ APIé‡è¯•: {DEFAULT_API_RETRY_TIMES} æ¬¡")
    except:
        logger.warning(f"âš ï¸  API_RETRY_TIMES å€¼æ— æ•ˆ: {api_retry_times}ï¼Œä½¿ç”¨é»˜è®¤å€¼ {DEFAULT_API_RETRY_TIMES} æ¬¡")
    
    logger.info("=" * 80)
    
    # è§£æè·¯å¾„æ˜ å°„
    path_mappings = []
    
    logger.info("")
    logger.info("ğŸ” è§£æé…ç½®...")
    
    if path_mappings_str:
        # ä½¿ç”¨æ–°çš„ PATH_MAPPINGS é…ç½®
        logger.info("ğŸ“‹ æ£€æµ‹åˆ° PATH_MAPPINGS é…ç½®ï¼ˆå¤šç»„æ˜ å°„æ¨¡å¼ï¼‰")
        path_mappings = parse_path_mappings(path_mappings_str)
        if not path_mappings:
            logger.error("")
            logger.error("=" * 80)
            logger.error("âŒ é”™è¯¯: PATH_MAPPINGS æ ¼å¼æ— æ•ˆ")
            logger.error("=" * 80)
            logger.error("")
            logger.error("æ ¼å¼è¯´æ˜:")
            logger.error("  æºè·¯å¾„1->ç›®æ ‡è·¯å¾„1,æºè·¯å¾„2->ç›®æ ‡è·¯å¾„2")
            logger.error("")
            logger.error("ç¤ºä¾‹:")
            logger.error("  PATH_MAPPINGS='/å¾…å¤„ç†/ä¸‹è½½->/å·²å®Œæˆ/è§†é¢‘,/ä¸´æ—¶/ç¼“å­˜->/å½’æ¡£/2024'")
            logger.error("")
            logger.error("æ³¨æ„äº‹é¡¹:")
            logger.error("  - è·¯å¾„å¿…é¡»ä»¥ '/' å¼€å¤´")
            logger.error("  - ä½¿ç”¨ '->' åˆ†éš”æºå’Œç›®æ ‡")
            logger.error("  - ä½¿ç”¨ ',' åˆ†éš”å¤šç»„æ˜ å°„")
            logger.error("=" * 80)
            return 1
    elif source_path and target_path:
        # ä½¿ç”¨æ—§çš„ SOURCE_PATH å’Œ TARGET_PATH é…ç½®ï¼ˆå…¼å®¹ï¼‰
        logger.info("ğŸ“‹ æ£€æµ‹åˆ° SOURCE_PATH/TARGET_PATH é…ç½®ï¼ˆå•ç»„æ˜ å°„æ¨¡å¼ï¼‰")
        path_mappings = [(source_path, target_path)]
        logger.info(f"âœ“ æ˜ å°„ 1: {source_path} -> {target_path}")
    else:
        logger.error("")
        logger.error("=" * 80)
        logger.error("âŒ é”™è¯¯: æœªè®¾ç½®è·¯å¾„æ˜ å°„é…ç½®")
        logger.error("=" * 80)
        logger.error("")
        logger.error("è¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è¿›è¡Œé…ç½®:")
        logger.error("")
        logger.error("æ–¹å¼1 - å¤šç»„æ˜ å°„ï¼ˆæ¨èï¼‰:")
        logger.error("  docker run -e PATH_MAPPINGS='/æº1->/ç›®æ ‡1,/æº2->/ç›®æ ‡2' ...")
        logger.error("")
        logger.error("æ–¹å¼2 - å•ç»„æ˜ å°„ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰:")
        logger.error("  docker run -e SOURCE_PATH='/å¾…å¤„ç†/ä¸‹è½½' \\")
        logger.error("             -e TARGET_PATH='/å·²å®Œæˆ/è§†é¢‘' ...")
        logger.error("")
        logger.error("ç¤ºä¾‹:")
        logger.error("  PATH_MAPPINGS='/å¾…å¤„ç†/ä¸‹è½½->/å·²å®Œæˆ/è§†é¢‘,/ä¸´æ—¶->/å½’æ¡£'")
        logger.error("=" * 80)
        return 1
    
    logger.info(f"âœ… æˆåŠŸè§£æ {len(path_mappings)} ç»„è·¯å¾„æ˜ å°„")
    
    # è§£ææ’é™¤çš„æ–‡ä»¶åç¼€
    exclude_extensions = parse_exclude_extensions(exclude_extensions_str)
    
    # éªŒè¯ç¯å¢ƒå˜é‡
    if mode == 'auto':
        # è§£ææ£€æŸ¥é—´éš”
        try:
            interval_minutes = int(check_interval)
            if interval_minutes < 2:
                logger.warning(f"âš ï¸  æ£€æŸ¥é—´éš” {interval_minutes} åˆ†é’Ÿè¿‡çŸ­ï¼Œå·²è°ƒæ•´ä¸ºæœ€å°å€¼ 2 åˆ†é’Ÿ")
                interval_minutes = 2
            logger.info(f"â° æ£€æŸ¥é—´éš”: {interval_minutes} åˆ†é’Ÿ")
        except:
            logger.error(f"âŒ é”™è¯¯: CHECK_INTERVAL å€¼æ— æ•ˆ: {check_interval}")
            logger.error("   å¿…é¡»æ˜¯æ•°å­—ï¼Œå•ä½ä¸ºåˆ†é’Ÿ")
            return 1
        
        # è§£ææ–‡ä»¶å¤§å°
        min_size_bytes = parse_file_size(min_file_size)
        if min_size_bytes is None:
            logger.error(f"âŒ é”™è¯¯: MIN_FILE_SIZE æ ¼å¼æ— æ•ˆ: {min_file_size}")
            logger.error("   æ”¯æŒæ ¼å¼: 200MB, 1.5GB, 500KB, 1TB ç­‰")
            return 1
        
        logger.info(f"ğŸ“ æœ€å°æ–‡ä»¶: {format_file_size(min_size_bytes)}")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    logger.info("")
    if not init_client_from_env():
        logger.error("")
        logger.error("=" * 80)
        logger.error("âŒ ç¨‹åºé€€å‡º: å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
        logger.error("=" * 80)
        return 1
    
    # è¿è¡Œè‡ªåŠ¨æ¨¡å¼
    logger.info("")
    if mode == 'auto':
        auto_move_files_task(path_mappings, interval_minutes, min_size_bytes, exclude_extensions)
    else:
        logger.error("=" * 80)
        logger.error(f"âŒ é”™è¯¯: ä¸æ”¯æŒçš„æ¨¡å¼: {mode}")
        logger.error("=" * 80)
        logger.error("å½“å‰Dockerç‰ˆæœ¬ä»…æ”¯æŒ auto æ¨¡å¼")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
